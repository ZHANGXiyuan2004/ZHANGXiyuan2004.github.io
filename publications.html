<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Publications â€” Shine Yuan</title>
  <link rel="stylesheet" href="assets/style.css">
  <link rel="preload" href="assets/audio/click.mp3" as="audio">
  <link rel="preload" href="assets/audio/levelup.mp3" as="audio">
  <script src="assets/script.js" defer></script>
</head>

<body>
  <div class="minecraft-bg"></div>
  <div class="minecraft-overlay"></div>
  <header class="site-header">
    <div class="container">
      <h1 class="site-title"><a href="index.html">Shine Yuan</a></h1>
      <button id="menu-toggle" aria-label="Toggle Menu">â˜°</button>
      <nav class="nav">
        <a href="index.html">Home</a>
        <a href="publications.html" class="active">Publications</a>
        <a href="blog.html">Blog</a>
        <a href="collaborators.html">Collaborators</a>
      </nav>
      <button id="theme-toggle" aria-label="Toggle Dark Mode"><span class="icon">ðŸŒ™</span></button>
    </div>
  </header>

  <main class="container">
    <div class="fade-in-up">
      <h3>ðŸ”¬ Research Interests</h3>
      <ul class="research-interests">
        <li><strong>Multimodal Data / Sensor Fusion</strong></li>
        <li><strong>AI for Science (AI4S)</strong></li>
      </ul>
    </div>
    <div class="fade-in-up">
      <h3>ðŸ“š Selected Research Projects</h3>
      <div class="filter-controls">
        <button class="filter-btn active" data-filter="all">All</button>
        <button class="filter-btn" data-filter="research">Research</button>
        <button class="filter-btn" data-filter="project">Projects</button>
      </div>

      <div class="pub-section fade-in-up">
        <div class="entry filter-item" data-category="project">
          <div class="pub-header">
            <h4>Mini-Onevision: Lightweight Multimodal Agent Framework with GRPO <br><span class="muted">Feb 2026 -
                Present</span></h4>
          </div>
          <p><strong>Goal</strong>: Build a lightweight Multimodal Large Language Model (MLLM) with
            <strong>Visual-Agentic</strong> capabilities. By integrating Qwen3-0.5B (Language Base) and SigLIP (Vision
            Encoder) and utilizing DeepSeek R1's Group Relative Policy Optimization (GRPO), the project aims to enhance
            logical reasoning and tool-use capabilities in low-compute environments.
          </p>

          <p><strong>Methodology</strong>:</p>
          <ul>
            <li><strong>Phase I: Architecture & Alignment</strong>. Using SigLIP as Vision Encoder and Qwen3-0.5B as LLM
              backbone. Designed and trained a projection layer to map visual features to language space. Pre-trained on
              LLaVA Bench datasets for basic image understanding.</li>
            <li><strong>Phase II: SFT Cold Start</strong>. Synthesized high-quality Tool-calling datasets (single-turn &
              multi-turn). Performed SFT cold start to enable basic Agent interaction formats (JSON output, API
              selection).</li>
            <li><strong>Phase III: Agentic RL with GRPO</strong>. Built a lightweight RL framework referencing
              Slime/Verl.
              Adopted <strong>GRPO</strong> algorithm combined with RAG & Search Tools, using retrieval accuracy and
              task
              completion as reward signals.</li>
          </ul>

          <p><strong>Key Advantages</strong>:</p>
          <ul>
            <li><strong>Low-Cost Training</strong>: Lightweight Qwen3-0.5B + SigLIP combination avoids high pre-training
              costs.</li>
            <li><strong>Reproducibility</strong>: Qwen3's rich embedded Agentic data supports strong Zero-shot Tool Use.
            </li>
            <li><strong>GRPO RL Paradigm</strong>: Replicates GRPO on a small multimodal model (low VRAM usage via Group
              sampling) to stimulate Chain-of-Thought generation and deep reasoning.</li>
            <li><strong>Visual Agentic Loop</strong>: Establishes a complete <strong>Perception -> Planning ->
                Action</strong> chain.</li>
          </ul>
        </div>

        <div class="entry filter-item" data-category="research">
          <div class="pub-header">
            <h4>Self-Powered Multimodal Emotion Recognition System <br><span class="muted">Dec 2023 - Aug 2024</span>
            </h4>
          </div>
          <p><strong>Lead Researcher</strong> | <em>Advisor:</em> <a
              href="https://faculty.uestc.edu.cn/zhengding/zh_CN/index.htm" target="_blank" rel="noopener">Prof. Ding
              Zheng (UESTC)</a></p>
          <p><strong>Project Introduction</strong>: Developed a wearable device integrating voice and EEG signal
            analysis
            for emotion detection.</p>
          <p><strong>Personal Contributions</strong>:</p>
          <ul>
            <li><strong>Completed the model architecture</strong>, designed a bimodal binding mechanism to process voice
              signals, combined modality-invariant and modality-specific features to input into the Transformer;
              designed
              a wavelet-transform-based preprocessing method to convert EEG signals into time-frequency image blocks to
              input into the Vision Transformer.</li>
            <li><strong>Prepared flexible organic photovoltaic devices</strong> using PM6:Y6 = 1:1.2 as the organic
              active
              layer and ITO-PET as the flexible cathode, achieving a photoelectric conversion efficiency of over 12.39%.
            </li>
          </ul>
          <p><strong>Achievements</strong>:
          <ul>
            <li>First-author paper accepted at <em>ICDT 2025</em> (Oral)</li>
            <li>First-author paper accepted at <em>ICASS 2026</em> (Oral)</li>
            <li>National First Prize in IoT Design Competition 2024</li>
            <li>National Innovation Training Program (Excellent Rating)</li>
            <li>4 National Invention Patents (Application Stage)</li>
          </ul>
          </p>
        </div>

        <div class="entry filter-item" data-category="research">
          <div class="pub-header">
            <h4>Superionic Conductor Materials Screening &amp; Phase Prediction <br><span class="muted">Jan 2025 - May
                2025</span></h4>
          </div>
          <p><strong>Lead Researcher</strong> | <em>Advisor:</em> <a
              href="https://sites.gc.sjtu.edu.cn/hong-zhu/sample-page/" target="_blank" rel="noopener">Prof. Hong Zhu
              (SJTU)</a></p>
          <p><strong>Project Introduction</strong>: Using a small amount of data on superionic conductor materials in
            the
            Li-N-S system, the general potential model MatterSim is fine-tuned, and then the fine-tuned model is used to
            screen the generation model MatterGen to obtain stable materials in the Li-N-S system.</p>
          <p><strong>Personal Contributions â€” Constructed an active learning loop</strong> to iteratively update the
            model
            and data:</p>
          <ul>
            <li>Used a small amount of labelled superionic conductor material data to train and test MatterSim.</li>
            <li>Generated unlabelled superionic conductor structures using MatterGen.</li>
            <li>Loaded MatterSim as a structure prediction model and used the Query By Committee method to obtain its
              uncertainty.</li>
            <li>Performed DFT calculations on the data with the highest uncertainty and added it to the training data
              for
              the next round of training.</li>
          </ul>
          <p><strong>Achievement</strong>: Selected for SJTU-Global College Research Internship Program 2025.</p>
        </div>
      </div>
  </main>

  <footer class="site-footer">
    <div class="container">
      <p><span class="footer-copyright">Â© 2024 Shine Yuan â€”</span><br><a
          href="https://ZHANGXiyuan2004.github.io">Website</a> | <a href="https://github.com/ZHANGXiyuan2004">GitHub</a>
      </p>
    </div>
  </footer>
  <div class="bottom-bar"></div>
  <!-- Minecraft Scene Decoration -->
  <div class="minecraft-scene">
    <img src="assets/board.png" alt="Board" class="mc-char board-anim">
  </div>

  <button id="back-to-top" aria-label="Back to Top">â†‘</button>
</body>

</html>